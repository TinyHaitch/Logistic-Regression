{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3ba47f5-42bd-45a3-88f6-2921d3d3a5f0",
   "metadata": {},
   "source": [
    "# This is the scratch implementation of Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19d2819f-5f63-4b7a-9bfa-3fd76ea30a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "824e760a-6315-4df0-ae9c-3a8633d139b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid of z\n",
    "    Args:\n",
    "        z (ndarray): A scalar, numpy array of any size.\n",
    "    Returns:\n",
    "        g (ndarray): sigmoid(z), with the same shape as z \n",
    "    \"\"\"\n",
    "\n",
    "    g = 1 / (1 + ((2.7)  ** (-z)))\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cea99211-2f0a-41f0-8a36-b825ea2b79b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function_logistic_reg(X, y, w, b, lambda_=0.5):\n",
    "    \"\"\"\n",
    "    Computes the cost over all examples\n",
    "    Args:\n",
    "      X : (ndarray Shape (m,n)) data, m examples by n features\n",
    "      y : (ndarray Shape (m,))  target value \n",
    "      w : (ndarray Shape (n,))  values of parameters of the model      \n",
    "      b : (scalar)              value of bias parameter of the model\n",
    "    Returns:\n",
    "      total_cost : (scalar) cost \n",
    "    \"\"\"\n",
    "    m, n = X.shape\n",
    "    cost = 0 \n",
    "\n",
    "    for i in range(m):\n",
    "        fwb = np.dot(X[i], w) + b\n",
    "        error = sigmoid(fwb)\n",
    "        cost += -((y[i] * np.log(error)) + ((1 - y[i]) * (np.log(1 - error)))) \n",
    "\n",
    "    cost  =  cost / m \n",
    "\n",
    "    # regularization\n",
    "    reg_cost = 0 \n",
    "    for j in range(n): \n",
    "        reg_cost +=  w[j] ** 2\n",
    "    reg_cost = (lambda_ / (2 * m)) * reg_cost\n",
    "\n",
    "    total_cost = cost + reg_cost\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e56d0bbb-a0e5-4b7a-8c7e-de4570ac0745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_compute(X, y, w, b, lambda_ = 0.5):\n",
    "    \"\"\"\n",
    "    Computes the gradient for logistic regression \n",
    " \n",
    "    Args:\n",
    "      X : (ndarray Shape (m,n)) data, m examples by n features\n",
    "      y : (ndarray Shape (m,))  target value \n",
    "      w : (ndarray Shape (n,))  values of parameters of the model      \n",
    "      b : (scalar)              value of bias parameter of the model\n",
    "    Returns\n",
    "      dj_dw : (ndarray Shape (n,)) The gradient of the cost w.r.t. the parameters w. \n",
    "      dj_db : (scalar)             The gradient of the cost w.r.t. the parameter b. \n",
    "    \"\"\"\n",
    "    \n",
    "    m, n = X.shape\n",
    "    dj_dw = np.zeros((n, ))\n",
    "    dj_db = 0. \n",
    "\n",
    "    for i in range(m): \n",
    "        fwb = np.dot(X[i], w) + b\n",
    "        error = sigmoid(fwb) - y[i]\n",
    "        for j in range(n):\n",
    "            dj_dw[j] += error + X[i, j]\n",
    "        dj_db += error\n",
    "\n",
    "    dj_dw = dj_dw / m  \n",
    "    dj_db = dj_db / m  \n",
    "\n",
    "    # regularized dj_dw\n",
    "    for j in range(n): \n",
    "        dj_dw[j] += (lambda_ / m) * w[j]\n",
    "\n",
    "    return dj_dw, dj_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba557c4-795b-483f-b004-adae0f821e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6cf3a0f2-b616-45e0-b4ee-4ad8f07f5180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, w_init, b_init, LR, iteration):\n",
    "    \"\"\"\n",
    "    Performs batch gradient descent to learn theta. Updates theta by taking \n",
    "    num_iters gradient steps with learning rate alpha\n",
    "    \n",
    "    Args:\n",
    "    X :    (ndarray Shape (m, n) data, m examples by n features\n",
    "    y :    (ndarray Shape (m,))  target value \n",
    "    w_in : (ndarray Shape (n,))  Initial values of parameters of the model\n",
    "    b_in : (scalar)              Initial value of parameter of the model\n",
    "    LR : (float)              Learning rate\n",
    "    iteration : (int)            number of iterations to run gradient descent\n",
    "    Returns:\n",
    "    w : (ndarray Shape (n,)) Updated values of parameters of the model after\n",
    "      running gradient descent\n",
    "    b : (scalar)                Updated value of parameter of the model after\n",
    "      running gradient descent\n",
    "    \"\"\"\n",
    "    \n",
    "    w = np.copy(w_init)\n",
    "    b = b_init\n",
    "    j_red = []\n",
    "    \n",
    "    for i in range(iteration):\n",
    "    \n",
    "        ## getting dj_dw, dj_db\n",
    "        dj_dw, dj_db = gradient_compute(X, y, w, b, lambda_ = 0.5)\n",
    "        \n",
    "        \n",
    "        w = w - LR * dj_dw\n",
    "        b = b - LR * dj_db\n",
    "        \n",
    "        # showing each step of J(w,b) reduction \n",
    "        j_red.append(cost_function_linear_reg(X, y, w, b, lambda_ = 0.5))\n",
    "        \n",
    "        if i% math.ceil(iteration/10) == 0: \n",
    "            print(j_red[-1], w, b)\n",
    "    \n",
    "    return w, b, j_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df56f1d-009d-4fa0-9e03-02e8c673964b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
